{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature evaluation\n",
    "\n",
    "org: **D4G**  project: **BGCO**  task: **feature evaluation**\n",
    "\n",
    "data: labeled (engage vs. static) dataset highlighting changes in member engagement (visits per week) between first and year of engagement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # used to manipulate dataframes\n",
    "\n",
    "import seaborn as sns  # needed for visualing\n",
    "import matplotlib.pyplot as plt  # needed for visualing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataframe\n",
    "df_001 = pd.read_csv(\"D4G_BGCO_Churn_Labeled.csv\", encoding = \"cp1252\")\n",
    "\n",
    "# edits\n",
    "df_002  # features with no unique values removed\n",
    "df_003 = df_002.drop(['member_identity', 'birth_year', 'age'], axis = 1)  # redundant features\n",
    "df_004 = df_003.drop(['member_number'], axis = 1)  # erroneous aggregation\n",
    "df_005  # missing values exceed 20%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The training set has {0} rows and {1} columns\".format(df_001.shape[0], df_001.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_001.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Summary\n",
    "\n",
    "Known\n",
    "* city: greater city of ottawa\n",
    "* province: ontario\n",
    "* postal_code\n",
    "* d4g_valid_postal_code\n",
    "\n",
    "Unknown\n",
    "* mem_type\n",
    "* active\n",
    "* d4g_school_id\n",
    "* grade\n",
    "* member_fees_total\n",
    "* suspended\n",
    "* camper\n",
    "* camp_year\n",
    "* subsidy\n",
    "* hear_about\n",
    "\n",
    "Proposed\n",
    "* visits per week or month\n",
    "* visits distribution, evenly throughout term, skewed early or late\n",
    "* age category\n",
    "* did member_location vary over the year?\n",
    "\n",
    "Key\n",
    "* d4g_member_id (primary key)\n",
    "\n",
    "Behaviour\n",
    "* label (target feature)\n",
    "\n",
    "Service\n",
    "* first_year: the first year of engagement\n",
    "* member_location: clubhouse visited\n",
    "\n",
    "Characteristic\n",
    "* Y1_Age: age at first_year\n",
    "* sex\n",
    "\n",
    "Removed\n",
    "* ethnic_origin (no unique)\n",
    "* member_type (no unique)\n",
    "* member_fee_paid_to_date (no unique)\n",
    "* member_fee_outstanding (no unique)\n",
    "* member_fees_total (no unique)\n",
    "* member_identity (= d4g_member_id)\n",
    "* birth_year (= age at first_year)\n",
    "* age (= age at first_year)\n",
    "* member_number (erroneous aggregation)\n",
    "* second_language (missing data)\n",
    "* other_language (missing data)\n",
    "* member_since (missing data)\n",
    "* last_renewal_date (missing data)\n",
    "* family_identity (missing data)\n",
    "\n",
    "Conditional Inclusions\n",
    "* first_language (only 60% of the dataset) (missing data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Values\n",
    "\n",
    "Number of unique values, if 1 or less should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_001.nunique()  # features with 0 and 1 unique value\n",
    "\n",
    "df_002.nunique()  # redundant features\n",
    "\n",
    "df_003.nunique()  # member_number, erroneous aggregation\n",
    "\n",
    "df_004.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "droplist_unique = [i for i in df_001.columns if df_001[i].nunique('label') < 2]\n",
    "df_002 = df_001.drop(droplist_unique,axis=1)\n",
    "\n",
    "droplist_unique  # from df_001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Member numbers\n",
    "* the duplicates in this feature seem to correspond to different members\n",
    "* thus inclusion erroneously reduces variability, without adding qualifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df_003.duplicated('member_number', keep = False)\n",
    "df_003_duplicates = df_003[duplicates]\n",
    "df_003_duplicates[['member_number','first_year','birth_year', 'sex', 'age', 'Y1_Age']].sort_values(by = 'member_number').head(6)\n",
    "#df_003_duplicates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "How many features/attributes have missing values? Which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"A total of \", len(df_004.columns[df_004.isnull().any()]), \"features have missing values\")\n",
    "print(\"They are:\", df_004.columns[df_004.isnull().any()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the percentage of missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss = df_004.isnull().sum()/len(df_004) #number of missing entries in each feature / number of total entries\n",
    "miss = miss[miss > 0] # keep only those that are greater than \"0 / number of total entries\"\n",
    "miss.sort_values(inplace=True) # sort by percentage ascending\n",
    "miss # display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss = miss.to_frame() # convert to a dataframe\n",
    "miss.columns = ['count'] # rename the column as 'count'\n",
    "miss.index.names = ['Name'] # rename index as 'Name'\n",
    "miss['Name'] = miss.index # create a new column of the index\n",
    "\n",
    "#plot the missing value count\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "sns.barplot(x = 'Name', y = 'count', data=miss)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove if exceeds 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "droplist_missing = [i for i in df_004.columns if df_004[i].isnull().sum()/len(df_004[i]) > 0.2]\n",
    "df_005 = df_004.drop(droplist_missing,axis=1)\n",
    "\n",
    "droplist_missing  # from df_004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace Missing Values (Tutorial_HousingPrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a pandas series, with neighborhood as key and grouped values\n",
    "lot_frontage_by_neighborhood = train['LotFrontage'].groupby(train['Neighborhood'])\n",
    "\n",
    "# for key (neighbourhood) and their grouped values in pandas series\n",
    "for key, group in lot_frontage_by_neighborhood:\n",
    "    \n",
    "    # replace any missing values (is.null) with group.median()\n",
    "    idx = (alldata['Neighborhood'] == key) & (alldata['LotFrontage'].isnull())\n",
    "    alldata.loc[idx, 'LotFrontage'] = group.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train['SalePrice'])\n",
    "\n",
    "print(\"The skewness of SalePrice is {}\".format(train['SalePrice'].skew()))\n",
    "\n",
    "print(\"The distribution has a right skew. Needs to be normalized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Log Transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.log(train['SalePrice'])\n",
    "print ('Skewness is', target.skew())\n",
    "sns.distplot(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Numeric and Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = train.select_dtypes(include=[np.number])\n",
    "cat_data = train.select_dtypes(exclude=[np.number])\n",
    "\n",
    "print (\"There are {} numeric and {} categorical columns in train \\\n",
    "data\".format(numeric_data.shape[1],cat_data.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = numeric_data.corr()\n",
    "sns.heatmap(corr, cmap=\"PiYG\", center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (corr['SalePrice'].sort_values(ascending=False)[:15], '\\n') #top 15 values\n",
    "print ('----------------------')\n",
    "print (corr['SalePrice'].sort_values(ascending=False)[-5:]) #last 5 values`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Specific Features\n",
    "\n",
    "Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['OverallQual'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's check the mean price per quality and plot it.\n",
    "pivot = train.pivot_table(index='GarageCars', values='GarageArea', aggfunc=np.median)\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.plot(kind='bar', color='goldenrod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GrLivArea variable\n",
    "sns.jointplot(x=train['GrLivArea'], y=train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_pivot = train.pivot_table(index='SaleCondition', values='SalePrice', aggfunc=np.median)\n",
    "sp_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_pivot.plot(kind='bar',color='teal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOVA: Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = [f for f in train.columns if train.dtypes[f] == 'object']\n",
    "def anova(frame):\n",
    "    anv = pd.DataFrame()\n",
    "    anv['features'] = cat\n",
    "    pvals = []\n",
    "    for c in cat:\n",
    "           samples = []\n",
    "           for cls in frame[c].unique():\n",
    "                  s = frame[frame[c] == cls]['SalePrice'].values\n",
    "                  samples.append(s)\n",
    "           pval = stats.f_oneway(*samples)[1]\n",
    "           pvals.append(pval)\n",
    "    anv['pval'] = pvals\n",
    "    return anv.sort_values('pval')\n",
    "\n",
    "cat_data['SalePrice'] = train.SalePrice.values\n",
    "k = anova(cat_data) \n",
    "k['disparity'] = np.log(1./k['pval'].values) \n",
    "sns.barplot(data=k, x = 'features', y='disparity') \n",
    "plt.xticks(rotation=90) \n",
    "plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_002 = df_001.dropna(axis=0)\n",
    "\n",
    "print(df_002.shape)\n",
    "print(df_002.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_003 = df_002.drop(['Codes','Lat_dm','Long_dm','Lat_dd','Long_dd','Wind_Speed'], axis = 1)\n",
    "\n",
    "print(df_003.shape)\n",
    "print(df_003.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
